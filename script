import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
#pip install wordcloud
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from sklearn import preprocessing
#pip install kmodes
from kmodes.kprototypes import KPrototypes
import seaborn as sns
import random
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
#pip install plotnine
from plotnine import *
import plotnine
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

#load the datasets
data1 = pd.read_excel(r'C:/Users/osann/OneDrive/Desktop/Data Science In Action Unified Survey (Risposte) (2).xlsx')
data2 = pd.read_excel(r'C:/Users/osann/OneDrive/Desktop/data science 2.xlsx')
data3 = pd.read_excel(r'C:/Users/osann/OneDrive/Desktop/data science completo.xlsx')

#rinominare data 3
data3.rename(columns = {"How would you describe your gender":"gender"}, inplace = True)
data3.rename(columns = {"Have you got insomnia problems?":"insomnia"}, inplace = True)
data3.rename(columns = {"Do you rather read a book or watch a movie?":"book_movie"}, inplace = True)
data3.rename(columns = {"What is your main source of daily news?":"daily_news"}, inplace = True)
data3.rename(columns = {"To contact someone, do you prefer a phone call or a text message?":"text_call"}, inplace = True)
data3.rename(columns = {"Do you consider yourself kind of bored?":"bored"}, inplace = True)
data3.rename(columns = {"In a social context do you find yourself using often the phone?":"phone_with_people"}, inplace = True)
data3.rename(columns = {"How many cigarettes do you smoke per day?":"cigarettes"}, inplace = True)
data3.rename(columns = {"What is the thing you value the most in your life (e.g. family, career, health, friendship etc.)?":"valuable_things"}, inplace = True)
data3.rename(columns = {"Do you feel happy?":"happiness"}, inplace = True)
data3.rename(columns = {"Do you monitor how many calories you acquire each day?":"calories"}, inplace = True)
data3.rename(columns = {"Do your parents smoke?":"smoking_parents"}, inplace = True)
data3.rename(columns = {"Are you anxious?":"anxiety"}, inplace = True)
data3.rename(columns = {"How many books do you read every year on average?":"books_year"}, inplace = True)
data3.rename(columns = {"How many times per week to you practice sport activity?":"sport_frequency"}, inplace = True)
data3.rename(columns = {"What is you age?":"age"}, inplace = True)
data3.rename(columns = {"Is one of your parents or both entrepreneur? ":"parents_ent"}, inplace = True)
data3.rename(columns = {"How many days do you think you can stay without a smartphone?":"days_without_phone"}, inplace = True)
data3.rename(columns = {"Have you ever looked at your phone to find out something (eg. Time) but got distracted and looked at something else forgetting the reason why you looked at your phone?":"phone_distraction"}, inplace = True)
data3.rename(columns = {"In your group of friends / people you hang out with, does the majority smoke?":"smoking_friends"}, inplace = True)
data3.rename(columns = {"Do you drink carbonated drinks?":"carbonated_drinks"}, inplace = True)
data3.rename(columns = {"How many hours on average do you spend using your phone in a day? (for a higher accuracy check the settings of your phone, please)":"phone_usage"}, inplace = True)
data3.rename(columns = {"How would you describe yourself? (please, give three words separate by a comma)":"self_description"}, inplace = True)
data3.rename(columns = {"Which sport do you practice?":"sport"}, inplace = True)
data3.rename(columns = {"From which university did you graduate? ":"uni"}, inplace = True)
data3.rename(columns = {"How do you think COVID-19 has affected your social life?":"covid_life"}, inplace = True)
data3.rename(columns = {"How stressed do you feel on a scale from 1 (no stressed) to 5 (highly stressed)?":"stress"}, inplace = True)
data3.rename(columns = {"How many languages do you speak fluently?":"languages"}, inplace = True)
data3.rename(columns = {"How many brothers or sisters do you have?":"bro_sis"}, inplace = True)
data3.rename(columns = {"How many books do you read every year on average?":"book_year"}, inplace = True)
data3.rename(columns = {"How many coffees are you having per day?":"coffee"}, inplace = True)
data3.rename(columns = {"What's your level of weekly alcohol assumption? ":"alcohol"}, inplace = True)
data3.rename(columns = {"How much do you care about nutrition and having a healthy lifestyle? ":"nutrition_care"}, inplace = True)
data3.rename(columns = {"At what time do you usually go to bed?":"bed_time"}, inplace = True)
data3.rename(columns = {"How many hours do you sleep per night on average?":"sleep_average"}, inplace = True)
data3.rename(columns = {"If you have one, what is (are) your favourite hobby(ies)?":"hobbies"}, inplace = True)
data3.rename(columns = {"What would you say is your best quality?":"best_quality"}, inplace = True)
data3.rename(columns = {"What do you do when you’re going through a personal crisis?":"personal_crisis"}, inplace = True)
data3.rename(columns = {"What's your parents’ degree level?":"parents_degree"}, inplace = True)
data3.rename(columns = {"How important is for you following a diet in your lifestyle? ":"diet"}, inplace = True)
data3.rename(columns = {"What is the field of your bachelor’s degree? ":"bachelor_degree"}, inplace = True)
data3.rename(columns = {"CHOOSE YOUR KEYWORD ;) format: aaaaaa00 - nothing that will remind of you. (eg. pizzamargherita26)":"keyword"}, inplace = True)
data3.rename(columns = {"Describe your typical evening in three words (please divide by a comma)":"evening"}, inplace = True)
data3.rename(columns = {"How many hours do you spend in hobbies per day?":"hobbies_time"}, inplace = True)
data3.rename(columns = {"How would you describe your gender":"gender"}, inplace = True)

#########DATA CLEANING
data3.isna().sum()

mean_phone = data3["phone_usage"].mean()
data3["phone_usage"] = data3["phone_usage"].replace(np.nan, mean_phone)

mean_sleep = data3["sleep_average"].mean()
data3["sleep_average"] = data3["sleep_average"].replace(np.nan, mean_sleep)

mean_hobbies = data3["hobbies_time"].mean()
data3["hobbies_time"] = data3["hobbies_time"].replace(np.nan, mean_hobbies)

data3["hobbies"] = data3["hobbies"].replace(np.nan, "none")
data3["covid_life"] = data3["covid_life"].replace(np.nan, "no answer")
data3["personal_crisis"] = data3["personal_crisis"].replace(np.nan, "no answer")
data3['sport_frequency'] = data3['sport_frequency'].replace(["I don't practice any sport"], [0])
data3['sport_frequency'] = data3['sport_frequency'].replace(["I don't practice any sports"], [0])
data3['sport_frequency'] = data3['sport_frequency'].replace(["More than 3 times per week"], [4])
data3['sport_frequency'] = data3['sport_frequency'].replace(["more than 3 times a week"], [4])

#levare colonna stress 1-7

data4 = data3.copy()
data4.drop('self_description', axis=1, inplace=True)
data4.drop('covid_life', axis=1, inplace=True)
data4.drop('bed_time', axis=1, inplace=True)
data4.drop('hobbies', axis=1, inplace=True)
data4.drop('best_quality', axis=1, inplace=True)
data4.drop('personal_crisis', axis=1, inplace=True)
data4.drop('keyword', axis=1, inplace=True)
data4.drop('evening', axis=1, inplace=True)
data4.drop('bachelor_degree', axis=1, inplace=True)
data4.drop('valuable_things', axis=1, inplace=True)
data4.drop('sport', axis=1, inplace=True)
data4.drop('uni', axis=1, inplace=True)
data4.drop('Do you consider yourself a stressed person? Answer from 1 to 7 (1 minimum level, 7 maximum level)', axis = 1, inplace = True)
data4.info()

data4.select_dtypes('object').nunique()
numerical = data4.describe()

#%%
#DATA VISUALIZATION

#CORRELATION MATRIX 
df = pd.DataFrame(data3,columns=['stress','sport_frequency', 'alcohol', 'coffee', 'nutrition_care','age','languages', 'phone_usage', 'sleep_average', 'diet', 'hobbies_time'])

corrMatrix = df.corr()
print (corrMatrix)
sns.heatmap(corrMatrix, annot=True)
plt.savefig('corr_matrix.png')
plt.show()

#%%
#####DATA EXPLORATION (FEATURES)

data4_anx = pd.DataFrame(data4['anxiety'].value_counts()).reset_index()
data4_anx['Percentage'] = data4_anx['anxiety'] / data4['anxiety'].value_counts().sum()
data4_anx.rename(columns = {'index':'anxiety', 'anxiety':'Total'}, inplace = True)
data4_anx = data4_anx.sort_values('Total', ascending = True).reset_index(drop = True)
# The dataframe
data4_anx = data4.groupby('anxiety').agg({
    'anxiety': 'count',
    'gender': lambda x: x.value_counts().index[0],
    'insomnia': lambda x: x.value_counts().index[0],
    'nutrition_care':'mean',
    'coffee':'mean',
    'diet':'mean',
    'age': 'mean',
    'phone_usage': 'mean',
    'stress': 'mean',
    'sleep_average': 'mean',
    'sport_frequency':'mean',
    'alcohol':'mean'
    
    }
).rename(columns = {'anxiety': 'Total'}).reset_index().sort_values('Total', ascending = True)


#%%
#LOGISTIC

data6 = data4.copy()
data6

data6.drop('uni', axis =1, inplace = True) 
data6.drop('phone_distraction', axis = 1, inplace = True )
data6.drop('sport', axis =1, inplace = True) 
data6.drop('book_movie', axis = 1, inplace = True)
data6.drop('parents_ent', axis = 1, inplace = True)
data6.drop('smoking_parents', axis =1, inplace = True) 
data6.drop('days_without_phone', axis =1, inplace = True)
data6.drop('books_year', axis =1, inplace = True)
data6.drop('valuable_things', axis =1, inplace = True)
data6.drop('parents_degree', axis =1, inplace = True)
data6.drop('bachelor_degree', axis =1, inplace = True)
data6.drop('stress', axis =1, inplace = True)
data6.drop('languages', axis =1, inplace = True)
data6.drop('bro_sis', axis =1, inplace = True)
data6.drop('daily_news', axis =1, inplace = True)
data6.drop('text_call', axis =1, inplace = True)
data6.drop('phone_with_people', axis =1, inplace = True)
data6.drop('carbonated_drinks', axis =1, inplace = True)
data6.drop('calories', axis =1, inplace = True)
scaler = preprocessing.MinMaxScaler()
data6[['age', 'sport_frequency', 'coffee', 'phone_usage', 'sleep_average', 'hobbies_time', 'alcohol', 'nutrition_care', 'diet']] = scaler.fit_transform(data6[['age', 'sport_frequency', 'coffee', 'phone_usage', 'sleep_average', 'hobbies_time', 'alcohol', 'nutrition_care', 'diet']])

data6.info()

data6 = pd.get_dummies(data6,
                        columns = ['gender','insomnia', 'bored', 'happiness', 'anxiety', 'smoking_friends','cigarettes'],
                        drop_first = True)
data6.info()
data6['anxiety_Yes']
y = data6.anxiety_Yes
#y.drop(y.columns[1], axis = 1)
X = data6.drop(['anxiety_Yes'], axis = 1, inplace = True)
X = data6
X.info()

# split X and y into training and testing sets

from sklearn.model_selection import train_test_split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)

# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(X_train,y_train)

#
y_pred=logreg.predict(X_test)

# import the metrics class
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix
plt.figure(figsize=(7,5))
sn.heatmap(cnf_matrix, annot=True)
# import required modules
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline


print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))

y_pred_proba = logreg.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()


#%%
#######CLUSTERING (ALGORITHM)
data4.info()
data44 = data4.copy()
cost = []
for cluster in range(1, 10):
    try:
        kprototype = KPrototypes(n_jobs = -1, n_clusters = cluster, init = 'Huang', random_state = 0)
        kprototype.fit_predict(data44, categorical = [0,3,4,6,8,10,12,13,14,15,20,21,22,23,25,26,27,28,29])
        cost.append(kprototype.cost_)
        print('Cluster initiation: {}'.format(cluster))
    except:
        break
    
data44_cost = pd.DataFrame({'Cluster':range(1, 10), 'Cost':cost})
data44_cost.head()

#pip install plotnine
from plotnine import *
import plotnine

p = plotnine.options.figure_size = (8, 4.8)
(
    ggplot(data = data44_cost)+
    geom_line(aes(x = 'Cluster',
                  y = 'Cost'))+
    geom_point(aes(x = 'Cluster',
                   y = 'Cost'))+
    geom_label(aes(x = 'Cluster',
                   y = 'Cost',
                   label = 'Cluster'),
               size = 10,
               nudge_y = 1000) +
    labs(title = 'Optimal number of cluster with Elbow Method')+
    xlab('Number of Clusters k')+
    ylab('Cost')+
    theme_minimal()
)

data44.info()
kprototype = KPrototypes(n_jobs = -1, n_clusters = 2, init = 'Huang', random_state = 0)
kprototype.fit_predict(data44, categorical = [0,3,4,6,8,10,12,13,14,15,20,21,22,23,25,26,27,28,29])
# Cluster centorid
kprototype.cluster_centroids_
# Check the iteration of the clusters created
kprototype.n_iter_
# Check the cost of the clusters created
kprototype.cost_
# Add the cluster to the dataframe
data44['Cluster Labels'] = kprototype.labels_
data44['Segment'] = data44['Cluster Labels'].map({0:'First', 1:'Second'})
# Order the cluster
data44['Segment'] = data44['Segment'].astype('category')
data44['Segment'] = data44['Segment'].cat.reorder_categories(['First','Second'])
data44.info()
data44.rename(columns = {'Cluster Labels':'Total'}, inplace = True)
data5 = data44.groupby('Segment').agg(
    {
        'Total':'count',
        'gender': lambda x: x.value_counts().index[0],
        'insomnia': lambda x: x.value_counts().index[0],
        'days_without_phone':lambda x: x.value_counts().index[0],
        'phone_distraction':lambda x: x.value_counts().index[0],
        'book_movie':lambda x: x.value_counts().index[0],
        'books_year':lambda x: x.value_counts().index[0],
        'daily_news':lambda x: x.value_counts().index[0],
        'text_call':lambda x: x.value_counts().index[0],
        'bored':lambda x: x.value_counts().index[0],
        'phone_with_people':lambda x: x.value_counts().index[0],
        'cigarettes':lambda x: x.value_counts().index[0],
        'happiness':lambda x: x.value_counts().index[0],
        'parents_ent':lambda x: x.value_counts().index[0],
        'parents_degree':lambda x: x.value_counts().index[0],
        'carbonated_drinks':lambda x: x.value_counts().index[0],
        'calories':lambda x: x.value_counts().index[0],
        'smoking_parents':lambda x: x.value_counts().index[0],
        'smoking_friends':lambda x: x.value_counts().index[0],
        'anxiety':lambda x: x.value_counts().index[0],
        'age': 'mean',
        'sport_frequency': 'mean',
        'languages': 'mean',
        'bro_sis': 'mean',
        'coffee': 'mean',
        'phone_usage':'mean',
        'sleep_average':'mean',
        'hobbies_time':'mean',
        'stress':'mean',
        'alcohol':'mean',
        'nutrition_care':'mean',
        'diet':'mean'
        
    }
).reset_index()
cc0 = data44[data44['Segment']== 'First']
cc1 = data44[data44['Segment']== 'Second']

sns.pairplot(data44,hue='Segment', palette='Dark2',diag_kind='kde',vars=["stress","phone_usage","sleep_average","hobbies_time"])

#BAR PLOT OF CLUSTERS   
X = ['coffee','alohol','phone_usage','stress', 'sport_freq', 'bro_sis', 'languages', 'sleep_av', 'hobbies', 'nutrition', 'diet']
YSegment1 = [2.69231,1.15385,2.87135,2.53846, 2.5,1.46154, 2.11538, 7.16642, 1.47692, 3.38462, 2.92308]
ZSegment2 = [1.55556,1.81481,5.39148,3.40741, 1.59259, 1, 2.33333, 7.48148,1.91481, 3.66667, 2.77778]
  
X_axis = np.arange(len(X))
  
plt.bar(X_axis - 0.2, YSegment1, 0.4, label = 'Segment 1', color = 'green')
plt.bar(X_axis + 0.2, ZSegment2, 0.4, label = 'Segment 2', color = 'red')  
plt.xticks(X_axis, X,rotation = 50)
plt.xlabel("Variables")
plt.ylabel("Frequency")
plt.title("Segment obtained comparison")
plt.legend()
plt.savefig('cluster.barplot11.png')
plt.show()
#%%
#########KNN FOR CC0 

#####REMOVING VARIABLES NOT USEFUL FOR THE ANALYSIS
cc0.drop('sport', axis=1, inplace=True)
cc0.drop('uni', axis=1, inplace=True)
cc0.drop('days_without_phone', axis=1, inplace=True)
cc0.drop('phone_distraction', axis=1, inplace=True)
cc0.drop('languages', axis=1, inplace=True)
cc0.drop('book_movie', axis=1, inplace=True)
cc0.drop('bro_sis', axis=1, inplace=True)
cc0.drop('daily_news', axis=1, inplace=True)
cc0.drop('text_call', axis=1, inplace=True)
cc0.drop('parents_ent', axis=1, inplace=True)
cc0.drop('parents_degree', axis=1, inplace=True)
cc0.drop('carbonated_drinks', axis=1, inplace=True)
cc0.drop('calories', axis=1, inplace=True)
cc0.drop('bachelor_degree', axis=1, inplace=True)
cc0.drop('smoking_parents', axis=1, inplace=True)
cc0.drop('phone_with_people', axis=1, inplace=True)
cc0.drop('books_year', axis=1, inplace=True)
cc0.drop('valuable_things', axis = 1, inplace = True)
cc0.drop('Total', axis = 1, inplace = True)
cc0.drop('Segment', axis = 1, inplace = True)

######DUMMIES (FEATURE ENGINEERING)

Y_dummy = pd.get_dummies(cc0['anxiety'])
dummy_vars = ['happiness','smoking_friends','gender','insomnia','bored','cigarettes']
other_dummies = pd.get_dummies(cc0[dummy_vars])
dummy_cc0 = pd.concat([Y_dummy,other_dummies], axis = 1)
dummy_cc0.head()

cc0 = pd.concat([cc0,dummy_cc0], axis = 1)
cc0.columns
cc0.drop(dummy_vars,axis=1,inplace=True)
cc0.info()

cc0.info()
cc0 = cc0.drop(['happiness_No','insomnia_No','gender_Female','bored_No','cigarettes_1 - 4','cigarettes_5 - 9','smoking_friends_No'],axis = 1)
cc0.drop(['anxiety','Yes'],axis=1,inplace=True)
cc0.info()
cc0.drop(['Total','Segment'],axis = 1, inplace = True)
cc0.info()

#K NN (ALGORITHM)
# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
#pip install pdfrom
import pandas as pd
from sklearn import metrics 
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.model_selection import train_test_split
import pandas as pd
# Importing the dataset
cc0.info()
X = cc0.iloc[:, [0,1,2,3,4,5,6,7,8,9,12,14,15]].values
y = cc0.iloc[:, 10].values
# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

len(X_train)
len(X_test)
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=2)
knn.fit(X_train, y_train.astype('int'))
KNeighborsClassifier(n_neighbors=2)
knn.score(X_test, y_test)
#0.71

from sklearn.metrics import confusion_matrix
y_pred = knn.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm
%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sn
plt.figure(figsize=(7,5))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.savefig('confusionmatrix_cc0.png')
plt.ylabel('Truth')



#########KNN FOR CC1 

cc1.drop('sport', axis=1, inplace=True)
cc1.drop('uni', axis=1, inplace=True)
cc1.drop('days_without_phone', axis=1, inplace=True)
cc1.drop('phone_distraction', axis=1, inplace=True)
cc1.drop('languages', axis=1, inplace=True)
cc1.drop('book_movie', axis=1, inplace=True)
cc1.drop('bro_sis', axis=1, inplace=True)
cc1.drop('daily_news', axis=1, inplace=True)
cc1.drop('text_call', axis=1, inplace=True)
cc1.drop('parents_ent', axis=1, inplace=True)
cc1.drop('parents_degree', axis=1, inplace=True)
cc1.drop('carbonated_drinks', axis=1, inplace=True)
cc1.drop('calories', axis=1, inplace=True)
cc1.drop('bachelor_degree', axis=1, inplace=True)
cc1.drop('smoking_parents', axis=1, inplace=True)
cc1.drop('phone_with_people', axis=1, inplace=True)
cc1.drop('books_year', axis=1, inplace=True)
cc1.drop('valuable_things', axis = 1, inplace = True)
cc1.drop('Segment', axis = 1, inplace = True)
cc1.drop('Total', axis = 1, inplace = True)

Y_dummy = pd.get_dummies(cc1['anxiety'])
dummy_vars = ['happiness','smoking_friends','gender','insomnia','bored','cigarettes']
other_dummies = pd.get_dummies(cc1[dummy_vars])
dummy_cc1 = pd.concat([Y_dummy,other_dummies], axis = 1)
dummy_cc1.head()

cc1 = pd.concat([cc1,dummy_cc1], axis = 1)
cc1.columns
cc1.drop(dummy_vars,axis=1,inplace=True)
cc1.info()

cc1.info()
cc1 = cc1.drop(['happiness_No','insomnia_No','gender_Female','bored_No','cigarettes_1 - 4','cigarettes_5-9','smoking_friends_No'],axis = 1)
cc1.drop(['anxiety','Yes'],axis=1,inplace=True)
cc1.info()
cc1.drop(['Total','Segment'],axis = 1, inplace = True)


cc1.info()
#K NN 
# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
#pip install pdfrom
import pandas as pdfrom 
from sklearn import metrics 
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.model_selection import train_test_split
import pandas as pd


# Importing the dataset
cc1.info()
X = cc0.iloc[:, [0,1,2,3,4,5,6,7,8,9,12,14,15,16]].values
y = cc0.iloc[:, 10].values

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

# Feature Scaling
from sklearn.preproctrain
len(X_test)
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=2)
knn.fit(X_train, y_train.astype('int'))
KNeighborsClassifier(n_neighbors=2)
knn.score(X_test, y_test)
print('kk.score = ', knn.score)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

########à

len(X_test, y_test)
#0.57

from sklearn.metrics import confusion_matrix
y_pred = knn.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm
%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sn
plt.figure(figsize=(7,5))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.savefig('confusionmatrix_cc1.png')
plt.ylabel('Truth')

